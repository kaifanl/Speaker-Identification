{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":260119,"status":"ok","timestamp":1692170151162,"user":{"displayName":"mei Mei","userId":"17063265026267386982"},"user_tz":-480},"id":"gtKxUzSgXKj3","outputId":"53bce90d-b9a7-4d09-9c89-1470a178267c"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-08-16 07:11:30--  https://github.com/googly-mingto/ML2023HW4/releases/download/data/Dataset.tar.gz.partaa\n","Resolving github.com (github.com)... 140.82.112.4\n","Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/606989982/7646b36b-6033-4a31-bac4-380c4d21d91e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230816%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230816T071130Z&X-Amz-Expires=300&X-Amz-Signature=e004459c7b5656ba32568134800ad2f277cc7e9beb8b9dab30a56db043dd2434&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=606989982&response-content-disposition=attachment%3B%20filename%3DDataset.tar.gz.partaa&response-content-type=application%2Foctet-stream [following]\n","--2023-08-16 07:11:31--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/606989982/7646b36b-6033-4a31-bac4-380c4d21d91e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230816%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230816T071130Z&X-Amz-Expires=300&X-Amz-Signature=e004459c7b5656ba32568134800ad2f277cc7e9beb8b9dab30a56db043dd2434&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=606989982&response-content-disposition=attachment%3B%20filename%3DDataset.tar.gz.partaa&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1560784333 (1.5G) [application/octet-stream]\n","Saving to: ‘Dataset.tar.gz.partaa’\n","\n","Dataset.tar.gz.part 100%[===================>]   1.45G   213MB/s    in 10s     \n","\n","2023-08-16 07:11:41 (142 MB/s) - ‘Dataset.tar.gz.partaa’ saved [1560784333/1560784333]\n","\n","--2023-08-16 07:11:41--  https://github.com/googly-mingto/ML2023HW4/releases/download/data/Dataset.tar.gz.partab\n","Resolving github.com (github.com)... 140.82.114.4\n","Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/606989982/95b45712-6e2f-4a52-96b1-7d88578345fc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230816%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230816T071141Z&X-Amz-Expires=300&X-Amz-Signature=50ce273901b992705888e51aa746069400f0fa455929eb0b7999d875c393fdb9&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=606989982&response-content-disposition=attachment%3B%20filename%3DDataset.tar.gz.partab&response-content-type=application%2Foctet-stream [following]\n","--2023-08-16 07:11:41--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/606989982/95b45712-6e2f-4a52-96b1-7d88578345fc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230816%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230816T071141Z&X-Amz-Expires=300&X-Amz-Signature=50ce273901b992705888e51aa746069400f0fa455929eb0b7999d875c393fdb9&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=606989982&response-content-disposition=attachment%3B%20filename%3DDataset.tar.gz.partab&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1560784333 (1.5G) [application/octet-stream]\n","Saving to: ‘Dataset.tar.gz.partab’\n","\n","Dataset.tar.gz.part 100%[===================>]   1.45G   161MB/s    in 13s     \n","\n","2023-08-16 07:11:54 (115 MB/s) - ‘Dataset.tar.gz.partab’ saved [1560784333/1560784333]\n","\n","--2023-08-16 07:11:54--  https://github.com/googly-mingto/ML2023HW4/releases/download/data/Dataset.tar.gz.partac\n","Resolving github.com (github.com)... 140.82.112.3\n","Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/606989982/0c9d42d3-95b7-4ca4-b57c-ab1a66a5564d?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230816%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230816T071155Z&X-Amz-Expires=300&X-Amz-Signature=a8e0e231c7a8111dcf5af71e1c0af2cfff716f4334034ca6801cf8226319d09f&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=606989982&response-content-disposition=attachment%3B%20filename%3DDataset.tar.gz.partac&response-content-type=application%2Foctet-stream [following]\n","--2023-08-16 07:11:55--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/606989982/0c9d42d3-95b7-4ca4-b57c-ab1a66a5564d?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230816%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230816T071155Z&X-Amz-Expires=300&X-Amz-Signature=a8e0e231c7a8111dcf5af71e1c0af2cfff716f4334034ca6801cf8226319d09f&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=606989982&response-content-disposition=attachment%3B%20filename%3DDataset.tar.gz.partac&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1560784333 (1.5G) [application/octet-stream]\n","Saving to: ‘Dataset.tar.gz.partac’\n","\n","Dataset.tar.gz.part 100%[===================>]   1.45G  8.44MB/s    in 17s     \n","\n","2023-08-16 07:12:12 (85.6 MB/s) - ‘Dataset.tar.gz.partac’ saved [1560784333/1560784333]\n","\n","--2023-08-16 07:12:12--  https://github.com/googly-mingto/ML2023HW4/releases/download/data/Dataset.tar.gz.partad\n","Resolving github.com (github.com)... 140.82.112.3\n","Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/606989982/0ee11da6-8c96-4463-b084-cea8f95d26e9?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230816%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230816T071212Z&X-Amz-Expires=300&X-Amz-Signature=00e58a501f23df17d2d9025594144339a3a1dd436e4a9c87a4b1c6524f29972a&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=606989982&response-content-disposition=attachment%3B%20filename%3DDataset.tar.gz.partad&response-content-type=application%2Foctet-stream [following]\n","--2023-08-16 07:12:12--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/606989982/0ee11da6-8c96-4463-b084-cea8f95d26e9?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230816%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230816T071212Z&X-Amz-Expires=300&X-Amz-Signature=00e58a501f23df17d2d9025594144339a3a1dd436e4a9c87a4b1c6524f29972a&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=606989982&response-content-disposition=attachment%3B%20filename%3DDataset.tar.gz.partad&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1560784336 (1.5G) [application/octet-stream]\n","Saving to: ‘Dataset.tar.gz.partad’\n","\n","Dataset.tar.gz.part 100%[===================>]   1.45G  56.3MB/s    in 15s     \n","\n","2023-08-16 07:12:28 (96.6 MB/s) - ‘Dataset.tar.gz.partad’ saved [1560784336/1560784336]\n","\n","tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.macl'\n"]}],"source":["!wget https://github.com/googly-mingto/ML2023HW4/releases/download/data/Dataset.tar.gz.partaa\n","!wget https://github.com/googly-mingto/ML2023HW4/releases/download/data/Dataset.tar.gz.partab\n","!wget https://github.com/googly-mingto/ML2023HW4/releases/download/data/Dataset.tar.gz.partac\n","!wget https://github.com/googly-mingto/ML2023HW4/releases/download/data/Dataset.tar.gz.partad\n","\n","!cat Dataset.tar.gz.part* > Dataset.tar.gz\n","!rm Dataset.tar.gz.partaa\n","!rm Dataset.tar.gz.partab\n","!rm Dataset.tar.gz.partac\n","!rm Dataset.tar.gz.partad\n","# unzip the file\n","!tar zxf Dataset.tar.gz\n","!rm Dataset.tar.gz"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1234,"status":"ok","timestamp":1692170152381,"user":{"displayName":"mei Mei","userId":"17063265026267386982"},"user_tz":-480},"id":"U6Y1cfpDfpON","outputId":"c1fc4f97-86a8-4eb0-de39-a9a53aa7c3fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["tar (child): Dataset.tar.gz: Cannot open: No such file or directory\n","tar (child): Error is not recoverable: exiting now\n","tar: Child returned status 2\n","tar: Error is not recoverable: exiting now\n"]}],"source":["!tar zxf Dataset.tar.gz"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E6burzCXIyuA"},"outputs":[],"source":["import numpy as np\n","import torch\n","import random\n","\n","def set_seed(seed):\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.benchmark = False\n","    torch.backends.cudnn.deterministic = True\n","\n","set_seed(87)"]},{"cell_type":"markdown","metadata":{"id":"k7dVbxW2LASN"},"source":["# Data\n","\n","## Dataset\n","- Original dataset is [Voxceleb2](https://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox2.html).\n","- The [license](https://creativecommons.org/licenses/by/4.0/) and [complete version](https://www.robots.ox.ac.uk/~vgg/data/voxceleb/files/license.txt) of Voxceleb2.\n","- We randomly select 600 speakers from Voxceleb2.\n","- Then preprocess the raw waveforms into mel-spectrograms.\n","\n","- Args:\n","  - data_dir: The path to the data directory.\n","  - metadata_path: The path to the metadata.\n","  - segment_len: The length of audio segment for training.\n","- The architecture of data directory \\\\\n","  - data directory \\\\\n","  |---- metadata.json \\\\\n","  |---- testdata.json \\\\\n","  |---- mapping.json \\\\\n","  |---- uttr-{random string}.pt \\\\\n","\n","- The information in metadata\n","  - \"n_mels\": The dimention of mel-spectrogram.\n","  - \"speakers\": A dictionary.\n","    - Key: speaker ids.\n","    - value: \"feature_path\" and \"mel_len\"\n","\n","\n","For efficiency, we segment the mel-spectrograms into segments in the traing step."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KpuGxl4CI2pr"},"outputs":[],"source":["import os\n","import json\n","import torch\n","import random\n","from pathlib import Path\n","from torch.utils.data import Dataset\n","from torch.nn.utils.rnn import pad_sequence\n","\n","\n","class myDataset(Dataset):\n","\tdef __init__(self, data_dir, segment_len=128):\n","\t\tself.data_dir = data_dir\n","\t\tself.segment_len = segment_len\n","\n","\t\t# Load the mapping from speaker neme to their corresponding id.\n","\t\tmapping_path = Path(data_dir) / \"mapping.json\"\n","\t\tmapping = json.load(mapping_path.open())\n","\t\tself.speaker2id = mapping[\"speaker2id\"]\n","\n","\t\t# Load metadata of training data.\n","\t\tmetadata_path = Path(data_dir) / \"metadata.json\"\n","\t\tmetadata = json.load(open(metadata_path))[\"speakers\"]\n","\n","\t\t# Get the total number of speaker.\n","\t\tself.speaker_num = len(metadata.keys())\n","\t\tself.data = []\n","\t\tfor speaker in metadata.keys():\n","\t\t\tfor utterances in metadata[speaker]:\n","\t\t\t\tself.data.append([utterances[\"feature_path\"], self.speaker2id[speaker]])\n","\n","\tdef __len__(self):\n","\t\t\treturn len(self.data)\n","\n","\tdef __getitem__(self, index):\n","\t\tfeat_path, speaker = self.data[index]\n","\t\t# Load preprocessed mel-spectrogram.\n","\t\tmel = torch.load(os.path.join(self.data_dir, feat_path))\n","\n","\t\t# Segmemt mel-spectrogram into \"segment_len\" frames.\n","\t\tif len(mel) > self.segment_len:\n","\t\t\t# Randomly get the starting point of the segment.\n","\t\t\t# The random segmentation is for avoiding overfitting.\n","\t\t\t# Every time we use different segmentations.\n","\t\t\t# BTW, mel-spectrogram contains both time and frequency information.\n","\t\t\tstart = random.randint(0, len(mel) - self.segment_len)\n","\t\t\t# Get a segment with \"segment_len\" frames.\n","\t\t\tmel = torch.FloatTensor(mel[start:start+self.segment_len])\n","\t\telse:\n","\t\t\tmel = torch.FloatTensor(mel)\n","\t\t# Turn the speaker id into long for computing loss later.\n","\t\tspeaker = torch.FloatTensor([speaker]).long()\n","\t\treturn mel, speaker\n","\n","\tdef get_speaker_number(self):\n","\t\treturn self.speaker_num"]},{"cell_type":"markdown","metadata":{"id":"668hverTMlGN"},"source":["## Dataloader\n","- Split dataset into training dataset(90%) and validation dataset(10%).\n","- Create dataloader to iterate the data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B7c2gZYoJDRS"},"outputs":[],"source":["import torch\n","from torch.utils.data import DataLoader, random_split\n","from torch.nn.utils.rnn import pad_sequence\n","\n","\n","def collate_batch(batch):\n","\t# Process features within a batch.\n","\t\"\"\"Collate a batch of data.\"\"\"\n","\tmel, speaker = zip(*batch)\n","\t# Because we train the model batch by batch, we need to pad the features in the same batch to make their lengths the same.\n","\t# When the length of mel is smaller than the segment_length, it will be kept.\n","\tmel = pad_sequence(mel, batch_first=True, padding_value=-20)    # pad log 10^(-20) which is very small value.\n","\t# mel: (batch size, length, 40)\n","\treturn mel, torch.FloatTensor(speaker).long()\n","\n","\n","def get_dataloader(data_dir, batch_size, n_workers):\n","\t\"\"\"Generate dataloader\"\"\"\n","\tdataset = myDataset(data_dir)\n","\tspeaker_num = dataset.get_speaker_number()\n","\t# Split dataset into training dataset and validation dataset\n","\ttrainlen = int(0.9 * len(dataset))\n","\tlengths = [trainlen, len(dataset) - trainlen]\n","\ttrainset, validset = random_split(dataset, lengths)\n","\n","\ttrain_loader = DataLoader(\n","\t\ttrainset,\n","\t\tbatch_size=batch_size,\n","\t\tshuffle=True,\n","\t\tdrop_last=True,\n","\t\tnum_workers=n_workers,\n","\t\tpin_memory=True,\n","\t\tcollate_fn=collate_batch,\n","\t)\n","\tvalid_loader = DataLoader(\n","\t\tvalidset,\n","\t\tbatch_size=batch_size,\n","\t\tnum_workers=n_workers,\n","\t\tdrop_last=True,\n","\t\tpin_memory=True,\n","\t\tcollate_fn=collate_batch,\n","\t)\n","\n","\treturn train_loader, valid_loader, speaker_num"]},{"cell_type":"markdown","metadata":{"id":"5FOSZYxrMqhc"},"source":["# Model\n","- TransformerEncoderLayer:\n","  - Base transformer encoder layer in [Attention Is All You Need](https://arxiv.org/abs/1706.03762)\n","  - Parameters:\n","    - d_model: the number of expected features of the input (required).\n","\n","    - nhead: the number of heads of the multiheadattention models (required).\n","\n","    - dim_feedforward: the dimension of the feedforward network model (default=2048).\n","\n","    - dropout: the dropout value (default=0.1).\n","\n","    - activation: the activation function of intermediate layer, relu or gelu (default=relu).\n","\n","- TransformerEncoder:\n","  - TransformerEncoder is a stack of N transformer encoder layers\n","  - Parameters:\n","    - encoder_layer: an instance of the TransformerEncoderLayer() class (required).\n","\n","    - num_layers: the number of sub-encoder-layers in the encoder (required).\n","\n","    - norm: the layer normalization component (optional)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iXZ5B0EKJGs8"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import math\n","\n","\n","class GLU(nn.Module):\n","\tdef __init__(self, dim):\n","\t\tsuper(GLU, self).__init__()\n","\t\tself.dim = dim\n","\n","\tdef forward(self, inputs):\n","\t\toutputs, gate = inputs.chunk(2, dim = self.dim)\n","\t\treturn outputs * gate.sigmoid()\n","\n","\n","class Transpose(nn.Module):\n","\tdef __init__(self, shape):\n","\t\tsuper().__init__()\n","\t\tself.shape = shape\n","\n","\tdef forward(self, inputs):\n","\t\treturn inputs.transpose(*self.shape)\n","\n","\n","class Linear(nn.Module):\n","\tdef __init__(self, in_dim, out_dim):\n","\t\tsuper().__init__()\n","\t\tself.linear =  nn.Linear(in_dim, out_dim)\n","\t\tnn.init.zeros_(self.linear.bias)\n","\t\tnn.init.xavier_uniform_(self.linear.weight)\n","\n","\tdef forward(self, inputs):\n","\t\treturn self.linear(inputs)\n","\n","\n","class PositionalEncoding(nn.Module):\n","\tdef __init__(self, d_model = 160, len = 128):\n","\t\tsuper().__init__()\n","\t\tself.pe = torch.zeros(len, d_model, requires_grad = False)\n","\t\tposition = torch.arange(0, len, dtype = torch.float).unsqueeze(1)\n","\t\tdiv_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n","\t\tself.pe[:, 0::2] = torch.sin(position * div_term)\n","\t\tself.pe[:, 1::2] = torch.cos(position * div_term)\n","\t\tself.pe = self.pe.unsqueeze(0)\n","\n","\tdef forward(self, length: int):\n","\t\treturn self.pe[:, :length]\n","\n","\n","class RelativeMultiHeadAttention(nn.Module):\n","\tdef __init__(self, d_model, num_heads):\n","\t\tsuper().__init__()\n","\t\t# Traditional attention\n","\t\tself.num_heads = num_heads\n","\t\tself.d_model = d_model\n","\t\tassert d_model % num_heads == 0, \"d_model % num_heads should be zero.\"\n","\t\tself.d_head = int(d_model / num_heads)\n","\n","\t\tself.proj_q = Linear(d_model, d_model)\n","\t\tself.proj_k = Linear(d_model, d_model)\n","\t\tself.proj_v = Linear(d_model, d_model)\n","\t\tself.proj_o = Linear(d_model, d_model)\n","\t\tself.proj_pos = Linear(d_model, d_model)\n","\t\tself.scale = math.sqrt(d_model)\n","\n","\t\t# Relative positional encoding\n","\t\tself.u = nn.Parameter(torch.Tensor(self.num_heads, self.d_head))\n","\t\tself.v = nn.Parameter(torch.Tensor(self.num_heads, self.d_head))\n","\t\tnn.init.xavier_uniform_(self.u)\n","\t\tnn.init.xavier_uniform_(self.v)\n","\n","\n","\tdef forward(self, inputs):\n","\t\tposition_encoding = PositionalEncoding(self.d_model, inputs.size(1))\n","\t\tbatch_size, seq_length = inputs.size(0), inputs.size(1)\n","\t\tdevice = torch.device(\"cuda\")\n","\t\tself.pos_encoding = position_encoding(seq_length).to(device)\n","\t\tself.pos_encoding = self.pos_encoding.repeat(batch_size, 1, 1)\n","\n","\t\tquery = self.proj_q(inputs).view(batch_size, -1, self.num_heads, self.d_head)\n","\t\t# key.shape = (batch_size, num_heads, seq_length, d_head) counted by num_heads\n","\t\tkey = self.proj_k(inputs).view(batch_size, -1, self.num_heads, self.d_head).permute(0, 2, 1, 3)\n","\t\tvalue = self.proj_v(inputs).view(batch_size, -1, self.num_heads, self.d_head).permute(0, 2, 1, 3)\n","\t\tpos_encoding = self.proj_pos(self.pos_encoding).view(batch_size, -1, self.num_heads, self.d_head)\n","\n","\t\t# Including content based addressing and content bias\n","\t\tcontent_score = torch.matmul((query + self.u).transpose(1, 2), key.transpose(2, 3))\n","\t\tpos_score = torch.matmul((query + self.v).transpose(1, 2), pos_encoding.permute(0, 2, 3, 1))\n","\t\t# It doesn't need relative shift because it may introduce wrong attention scores\n","\t\t# and we don't need mask in this task.\n","\t\tscore = (content_score + pos_score) / self.scale\n","\t\tattn_score = F.softmax(score, -1)\n","\t\t# out: (batch_size, seq_length, num_heads, d_head)\n","\t\tout = torch.matmul(attn_score, value).transpose(1, 2)\n","\t\tout = out.reshape(batch_size, -1, self.d_model)\n","\n","\t\treturn self.proj_o(out)\n","\n","\n","class Classifier(nn.Module):\n","\tdef __init__(self,\n","\t             d_model=160,\n","\t             n_spks=600,\n","\t\t\t\t\t\t\t dropout=0.1,\n","\t\t\t\t\t\t\t expansion = 2,\n","\t\t\t\t\t\t\t in_channels = 128,\n","\t             kernel_size = 3):\n","\t\tsuper().__init__()\n","\t\t# Project the dimension of features from that of input into d_model.\n","\t\tself.prenet = nn.Linear(40, d_model)\n","\t\t# TODO:\n","\t\t#   Change Transformer to Conformer.\n","\t\t#   https://arxiv.org/abs/2005.08100\n","\t\tself.MultiHeadSelfAttention = nn.Sequential(\n","\t\t\t\tnn.LayerNorm(d_model),\n","\t\t\t\tRelativeMultiHeadAttention(d_model = d_model, num_heads = 8),\n","\t\t\t\tnn.Dropout(p = dropout)\n","\t\t)\n","\n","\t\tself.ConvolutionModule = nn.Sequential(\n","\t\t\t\tnn.LayerNorm(d_model),\n","\t\t\t\tTranspose((1, 2)),\n","\t\t\t\tnn.Conv1d(in_channels = d_model,\n","\t\t\t\t          out_channels = expansion * d_model,\n","\t\t\t\t\t\t\t\t\tkernel_size = 1,\n","\t\t\t\t\t\t\t\t\tstride = 1),\n","\t\t\t\tGLU(dim = 1),\n","\t\t\t\tnn.Conv1d(in_channels = d_model,\n","\t\t\t\t          out_channels = d_model,\n","\t\t\t\t\t\t\t\t\tkernel_size = kernel_size,\n","\t\t\t\t\t\t\t\t\tstride = 1,\n","\t\t\t\t\t\t\t\t\tpadding = (kernel_size - 1) // 2,\n","\t\t\t\t\t\t\t\t\tgroups = d_model),\n","\t\t\t\tnn.BatchNorm1d(d_model),\n","\t\t\t\tnn.SiLU(),\n","\t\t\t\tnn.Conv1d(in_channels = d_model,\n","\t\t\t\t          out_channels = d_model,\n","\t\t\t\t\t\t\t\t\tkernel_size = 1,\n","\t\t\t\t\t\t\t\t\tstride = 1),\n","\t\t\t\tTranspose((1, 2)),\n","\t\t\t\tnn.Dropout(p = dropout)\n","\t\t)\n","\n","\t\tself.FeedForwardModule = nn.Sequential(\n","\t\t\t\tnn.LayerNorm(d_model),\n","\t\t\t\tnn.Linear(d_model, d_model * 4),\n","\t\t\t\tnn.SiLU(),\n","\t\t\t\tnn.Dropout(p = dropout),\n","\t\t\t\tnn.Linear(d_model * 4, d_model),\n","\t\t\t\tnn.Dropout(p = dropout)\n","\t\t)\n","\t\t# self.encoder_layer = nn.TransformerEncoderLayer(\n","\t\t# \td_model=d_model, dim_feedforward=256, nhead=8\n","\t\t# )\n","\t\t# self.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=2)\n","\n","\t\t# Project the the dimension of features from d_model into speaker nums.\n","\t\tself.pred_layer = nn.Sequential(\n","\t\t\tnn.Linear(d_model, d_model * 2),\n","\t\t\tnn.ReLU(),\n","\t\t\tnn.Linear(d_model * 2, n_spks),\n","\t\t)\n","\n","\t\tself.LayerNorm = nn.LayerNorm(d_model)\n","\n","\tdef forward(self, mels):\n","\t\t\"\"\"\n","\t\targs:\n","\t\t\tmels: (batch size, length, 40)\n","\t\treturn:\n","\t\t\tout: (batch size, n_spks)\n","\t\t\"\"\"\n","\t\t# out: (batch size, length, d_model)\n","\t\tout = self.prenet(mels)\n","\n","\t\tout = out + self.FeedForwardModule(out) / 2\n","\n","\t\tout = out + self.MultiHeadSelfAttention(out)\n","\n","\t\tout = out + self.ConvolutionModule(out)\n","\n","\t\tout = out + self.FeedForwardModule(out) / 2\n","\n","\t\tout = self.LayerNorm(out)\n","\t\t# out: (length, batch size, d_model)\n","\t\t# out = out.permute(1, 0, 2)\n","\t\t# The encoder layer expect features in the shape of (length, batch size, d_model).\n","\t\t# out = self.encoder_layer(out)\n","\t\t# out: (batch size, length, d_model)\n","\t\t# out = out.transpose(0, 1)\n","\t\t# mean pooling\n","\t\tstats = out.mean(dim=1)\n","\n","\t\t# out: (batch, n_spks)\n","\t\tout = self.pred_layer(stats)\n","\t\treturn out"]},{"cell_type":"markdown","metadata":{"id":"W7yX8JinM5Ly"},"source":["# Learning rate schedule\n","- For transformer architecture, the design of learning rate schedule is different from that of CNN.\n","- Previous works show that the warmup of learning rate is useful for training models with transformer architectures.\n","- The warmup schedule\n","  - Set learning rate to 0 in the beginning.\n","  - The learning rate increases linearly from 0 to initial learning rate during warmup period."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ykt0N1nVJJi2"},"outputs":[],"source":["import math\n","\n","import torch\n","from torch.optim import Optimizer\n","from torch.optim.lr_scheduler import LambdaLR\n","\n","\n","def get_cosine_schedule_with_warmup(\n","\toptimizer: Optimizer,\n","\tnum_warmup_steps: int,\n","\tnum_training_steps: int,\n","\tnum_cycles: float = 0.5,\n","\tlast_epoch: int = -1,\n","):\n","\t\"\"\"\n","\tCreate a schedule with a learning rate that decreases following the values of the cosine function between the\n","\tinitial lr set in the optimizer to 0, after a warmup period during which it increases linearly between 0 and the\n","\tinitial lr set in the optimizer.\n","\n","\tArgs:\n","\t\toptimizer (:class:`~torch.optim.Optimizer`):\n","\t\tThe optimizer for which to schedule the learning rate.\n","\t\tnum_warmup_steps (:obj:`int`):\n","\t\tThe number of steps for the warmup phase.\n","\t\tnum_training_steps (:obj:`int`):\n","\t\tThe total number of training steps.\n","\t\tnum_cycles (:obj:`float`, `optional`, defaults to 0.5):\n","\t\tThe number of waves in the cosine schedule (the defaults is to just decrease from the max value to 0\n","\t\tfollowing a half-cosine).\n","\t\tlast_epoch (:obj:`int`, `optional`, defaults to -1):\n","\t\tThe index of the last epoch when resuming training.\n","\n","\tReturn:\n","\t\t:obj:`torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.\n","\t\"\"\"\n","\tdef lr_lambda(current_step):\n","\t\t# Warmup\n","\t\tif current_step < num_warmup_steps:\n","\t\t\treturn float(current_step) / float(max(1, num_warmup_steps))\n","\t\t# decadence\n","\t\tprogress = float(current_step - num_warmup_steps) / float(\n","\t\t\tmax(1, num_training_steps - num_warmup_steps)\n","\t\t)\n","\t\treturn max(\n","\t\t\t0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))\n","\t\t)\n","\n","\treturn LambdaLR(optimizer, lr_lambda, last_epoch)"]},{"cell_type":"markdown","metadata":{"id":"-LN2XkteM_uH"},"source":["# Model Function\n","- Model forward function."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N-rr8529JMz0"},"outputs":[],"source":["import torch\n","\n","\n","def model_fn(batch, model, criterion, device):\n","\t\"\"\"Forward a batch through the model.\"\"\"\n","\n","\tmels, labels = batch\n","\tmels = mels.to(device)\n","\tlabels = labels.to(device)\n","\n","\touts = model(mels)\n","\n","\tloss = criterion(outs, labels)\n","\n","\t# Get the speaker id with highest probability.\n","\tpreds = outs.argmax(1)\n","\t# Compute accuracy.\n","\taccuracy = torch.mean((preds == labels).float())\n","\n","\treturn loss, accuracy"]},{"cell_type":"markdown","metadata":{"id":"cwM_xyOtNCI2"},"source":["# Validate\n","- Calculate accuracy of the validation set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YAiv6kpdJRTJ"},"outputs":[],"source":["from tqdm import tqdm\n","import torch\n","\n","\n","def valid(dataloader, model, criterion, device):\n","\t\"\"\"Validate on validation set.\"\"\"\n","\n","\tmodel.eval()\n","\trunning_loss = 0.0\n","\trunning_accuracy = 0.0\n","\tpbar = tqdm(total=len(dataloader.dataset), ncols=0, desc=\"Valid\", unit=\" uttr\")\n","\n","\tfor i, batch in enumerate(dataloader):\n","\t\twith torch.no_grad():\n","\t\t\tloss, accuracy = model_fn(batch, model, criterion, device)\n","\t\t\trunning_loss += loss.item()\n","\t\t\trunning_accuracy += accuracy.item()\n","\n","\t\tpbar.update(dataloader.batch_size)\n","\t\tpbar.set_postfix(\n","\t\t\tloss=f\"{running_loss / (i+1):.2f}\",\n","\t\t\taccuracy=f\"{running_accuracy / (i+1):.2f}\",\n","\t\t)\n","\n","\tpbar.close()\n","\tmodel.train()\n","\n","\treturn running_accuracy / len(dataloader)"]},{"cell_type":"markdown","metadata":{"id":"g6ne9G-eNEdG"},"source":["# Main function"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Usv9s-CuJSG7","outputId":"2e3cfc4d-6a1a-411a-9e4f-a4cc1e236fa8"},"outputs":[{"output_type":"stream","name":"stdout","text":["[Info]: Use cuda now!\n","[Info]: Finish loading data!\n","[Info]: Finish creating model!\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100% 2000/2000 [01:55<00:00, 17.33 step/s, accuracy=0.34, loss=3.26, step=2000]\n","Valid: 100% 5664/5667 [00:12<00:00, 469.93 uttr/s, accuracy=0.26, loss=3.41]\n","Train:   5% 102/2000 [00:03<01:12, 26.35 step/s, accuracy=0.09, loss=4.18, step=2102]"]}],"source":["from tqdm import tqdm\n","\n","import torch\n","import torch.nn as nn\n","from torch.optim import AdamW\n","from torch.utils.data import DataLoader, random_split\n","\n","\n","def parse_args():\n","\t\"\"\"arguments\"\"\"\n","\tconfig = {\n","\t\t\"data_dir\": \"./Dataset\",\n","\t\t\"save_path\": \"model.ckpt\",\n","\t\t\"batch_size\": 32,\n","\t\t\"n_workers\": 8,\n","\t\t\"valid_steps\": 2000,\n","\t\t\"warmup_steps\": 1000,\n","\t\t\"save_steps\": 10000,\n","\t\t\"total_steps\": 70000,\n","\t}\n","\n","\treturn config\n","\n","\n","def main(\n","\tdata_dir,\n","\tsave_path,\n","\tbatch_size,\n","\tn_workers,\n","\tvalid_steps,\n","\twarmup_steps,\n","\ttotal_steps,\n","\tsave_steps,\n","):\n","\t\"\"\"Main function.\"\"\"\n","\tdevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\tprint(f\"[Info]: Use {device} now!\")\n","\n","\ttrain_loader, valid_loader, speaker_num = get_dataloader(data_dir, batch_size, n_workers)\n","\ttrain_iterator = iter(train_loader)\n","\tprint(f\"[Info]: Finish loading data!\",flush = True)\n","\n","\tmodel = Classifier(n_spks=speaker_num).to(device)\n","\tcriterion = nn.CrossEntropyLoss()\n","\toptimizer = AdamW(model.parameters(), lr=1e-3)\n","\tscheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n","\tprint(f\"[Info]: Finish creating model!\",flush = True)\n","\n","\tbest_accuracy = -1.0\n","\tbest_state_dict = None\n","\n","\tpbar = tqdm(total=valid_steps, ncols=0, desc=\"Train\", unit=\" step\")\n","\n","\tfor step in range(total_steps):\n","\t\t# Get data\n","\t\ttry:\n","\t\t\tbatch = next(train_iterator)\n","\t\texcept StopIteration:\n","\t\t\ttrain_iterator = iter(train_loader)\n","\t\t\tbatch = next(train_iterator)\n","\n","\t\tloss, accuracy = model_fn(batch, model, criterion, device)\n","\t\tbatch_loss = loss.item()\n","\t\tbatch_accuracy = accuracy.item()\n","\n","\t\t# Updata model\n","\t\tloss.backward()\n","\t\toptimizer.step()\n","\t\tscheduler.step()\n","\t\toptimizer.zero_grad()\n","\n","\t\t# Log\n","\t\tpbar.update()\n","\t\tpbar.set_postfix(\n","\t\t\tloss=f\"{batch_loss:.2f}\",\n","\t\t\taccuracy=f\"{batch_accuracy:.2f}\",\n","\t\t\tstep=step + 1,\n","\t\t)\n","\n","\t\t# Do validation\n","\t\tif (step + 1) % valid_steps == 0:\n","\t\t\tpbar.close()\n","\n","\t\t\tvalid_accuracy = valid(valid_loader, model, criterion, device)\n","\n","\t\t\t# keep the best model\n","\t\t\tif valid_accuracy > best_accuracy:\n","\t\t\t\tbest_accuracy = valid_accuracy\n","\t\t\t\tbest_state_dict = model.state_dict()\n","\n","\t\t\tpbar = tqdm(total=valid_steps, ncols=0, desc=\"Train\", unit=\" step\")\n","\n","\t\t# Save the best model so far.\n","\t\tif (step + 1) % save_steps == 0 and best_state_dict is not None:\n","\t\t\ttorch.save(best_state_dict, save_path)\n","\t\t\tpbar.write(f\"Step {step + 1}, best model saved. (accuracy={best_accuracy:.4f})\")\n","\n","\tpbar.close()\n","\n","\n","if __name__ == \"__main__\":\n","\tmain(**parse_args())"]},{"cell_type":"markdown","metadata":{"id":"NLatBYAhNNMx"},"source":["# Inference\n","\n","## Dataset of inference"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"efS4pCmAJXJH"},"outputs":[],"source":["import os\n","import json\n","import torch\n","from pathlib import Path\n","from torch.utils.data import Dataset\n","\n","\n","class InferenceDataset(Dataset):\n","\tdef __init__(self, data_dir):\n","\t\ttestdata_path = Path(data_dir) / \"testdata.json\"\n","\t\tmetadata = json.load(testdata_path.open())\n","\t\tself.data_dir = data_dir\n","\t\tself.data = metadata[\"utterances\"]\n","\n","\tdef __len__(self):\n","\t\treturn len(self.data)\n","\n","\tdef __getitem__(self, index):\n","\t\tutterance = self.data[index]\n","\t\tfeat_path = utterance[\"feature_path\"]\n","\t\tmel = torch.load(os.path.join(self.data_dir, feat_path))\n","\n","\t\treturn feat_path, mel\n","\n","\n","def inference_collate_batch(batch):\n","\t\"\"\"Collate a batch of data.\"\"\"\n","\tfeat_paths, mels = zip(*batch)\n","\n","\treturn feat_paths, torch.stack(mels)"]},{"cell_type":"markdown","metadata":{"id":"tl0WnYwxNK_S"},"source":["## Main funcrion of Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i8SAbuXEJb2A"},"outputs":[],"source":["import json\n","import csv\n","from pathlib import Path\n","from tqdm.notebook import tqdm\n","\n","import torch\n","from torch.utils.data import DataLoader\n","\n","def parse_args():\n","\t\"\"\"arguments\"\"\"\n","\tconfig = {\n","\t\t\"data_dir\": \"./Dataset\",\n","\t\t\"model_path\": \"./model.ckpt\",\n","\t\t\"output_path\": \"./output.csv\",\n","\t}\n","\n","\treturn config\n","\n","\n","def main(\n","\tdata_dir,\n","\tmodel_path,\n","\toutput_path,\n","):\n","\t\"\"\"Main function.\"\"\"\n","\tdevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\tprint(f\"[Info]: Use {device} now!\")\n","\n","\tmapping_path = Path(data_dir) / \"mapping.json\"\n","\tmapping = json.load(mapping_path.open())\n","\n","\tdataset = InferenceDataset(data_dir)\n","\tdataloader = DataLoader(\n","\t\tdataset,\n","\t\tbatch_size=1,\n","\t\tshuffle=False,\n","\t\tdrop_last=False,\n","\t\tnum_workers=8,\n","\t\tcollate_fn=inference_collate_batch,\n","\t)\n","\tprint(f\"[Info]: Finish loading data!\",flush = True)\n","\n","\tspeaker_num = len(mapping[\"id2speaker\"])\n","\tmodel = Classifier(n_spks=speaker_num).to(device)\n","\tmodel.load_state_dict(torch.load(model_path))\n","\tmodel.eval()\n","\tprint(f\"[Info]: Finish creating model!\",flush = True)\n","\n","\tresults = [[\"Id\", \"Category\"]]\n","\tfor feat_paths, mels in tqdm(dataloader):\n","\t\twith torch.no_grad():\n","\t\t\tmels = mels.to(device)\n","\t\t\touts = model(mels)\n","\t\t\tpreds = outs.argmax(1).cpu().numpy()\n","\t\t\tfor feat_path, pred in zip(feat_paths, preds):\n","\t\t\t\tresults.append([feat_path, mapping[\"id2speaker\"][str(pred)]])\n","\n","\twith open(output_path, 'w', newline='') as csvfile:\n","\t\twriter = csv.writer(csvfile)\n","\t\twriter.writerows(results)\n","\n","\n","if __name__ == \"__main__\":\n","\tmain(**parse_args())"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1u-610KA-urqfJjDH5O0pecwfP--V9DQs","timestamp":1692170996976}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}